 ~/.dropbox-dist/dropboxd&

10.17.20.81 diamante
10.17.20.88 esmeralda		
10.17.20.87 rubi		
10.17.20.86 quartzo			
10.17.20.85 turmalina		
10.17.20.84 turquesa	(03)	
10.17.20.82 ametista	
10.17.20.83 granada


como iniciar um teste

A) Preparar o ambiente
SLAVES=turmalina, turquesa

1- logar 				su - hadoop
2- pasta do hadoop 			cd /usr/local/hadoop/
3- verificar hosts no arquivo 		vi conf/core-site.xml 
(colocar nos arquivos dos slaves endereço e porta do master)
3.1-incluir o número de hosts a duplicar os arquivos	vi conf/hdfs-site.xml
(The default value of dfs.replication is 3. However, we have only two nodes available, so we set dfs.replication to 2.)
4- parar todos os serviços ativos	bin/stop-all.sh
5- verificar as conexões		ssh localhost e ssh SLAVES
6- iniciar os serviços do hadoop
6.1- iniciar HDFS 			bin/start-dfs.sh
(nameNode master e dataNode nos slaves)
6.2- iniciar MapReduce			bin/start-mapred.sh
7- verificar master			jps e tailf logs/hadoop-hadoop-datanode-ametista.log 
8- verificar slave			jps e tailf logs/hadoop-hadoop-datanode-SLAVES.log
9- paineis do hadoop			http://localhost:50030/jobtracker.jsp
					http://localhost:50070/dfshealth.jsp

B) Execução
1- copiar arquivos que serão testado para o dfs
bin/hadoop dfs -copyFromLocal /home/marianehadoop/clusterdata/wordcount/ /user/marianehadoop/wordcount


1.5 eliminar os arquivos existentes


2- run
bin/hadoop jar hadoop*examples*.jar wordcount /user/marianehadoop/wordcount /user/marianehadoop/wordcount-output

3- se quiser copiar os resultados
bin/hadoop dfs -getmerge /user/marianehadoop/wordcount-output /home/marianehadoop/clusterdata/wordcount/

4- teste do pi
bin/hadoop jar hadoop-*-examples.jar pi 10 10000000 > 
