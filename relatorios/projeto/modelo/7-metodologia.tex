\chapter{Desenvolvimento}
\label{cap:desenvolvimento}

\section{Metodologia}

A primeira fase do projeto será destinado ao estudo mais detalhado da computação paralela, em especial os algoritmos de ordenação paralela, dos fatores que influenciam o desempenho de tais algoritmos, o modelo MapReduce e a plataforma Hadoop. O passo seguinte é conhecer detalhadamente o algoritmo paralelo a ser implementado e definir as estratégias para sua implentação ambiente Hadoop. 
O algoritmo implementado deve ser cuidadosamente avaliado para verificar um funcionamento adequado com diferentes entradas e número de máquinas. 

Em seguida, serão realizados experimentos para testes de desempenho dos algoritmos com relação à quantidade de máquinas, quantidade de dados e conjunto de dados.  Os resultados obtidos serão analisados e permitirão comparar a desempenho dos algoritmos em cada situação. 


\section{Infraestrutura}

A infra estrutura necessária ao desenvolvimento do projeto será fornecida pelo Laboratório de Redes e Sistemas (LABORES) do Departamento de Computação (DECOM). O laboratório possui um \textit{cluster} formado por cinco máquinas Dell Optiplex 380, que serão utilizadas na realização dos testes dos algoritmos. Os algoritmos serão desenvolvidos em linguagem Java, de acordo com o modelo MapReduce, no ambiente Hadoop. 

Cada máquina do \textit{cluster} apresenta as seguintes características:
\begin{packed_enum}
\item Processador Intel Core 2 Duo de 3.0 GHz
\item Disco rígido SATA de 500 GB 7200 RPM
\item Memória RAM de 4 GB
\item Placa de rede Gigabit Ethernet
\item Sistema operacional Linux Ubunbu 10.04 32 bits %(kernel 2.6.\textbf{XX})
\item Sun Java JDK 1.6.0 19.0-b09 
\item Apache Hadoop 1.0.2
\end{packed_enum}


\section{Descrição dos experimentos}

A primeira parte dos experimentos consitiu em reproduzir os resultados já encontrados no trabalho de referência: testes de ordenação com os \textit{benchmarks} TeraSort e Sort, e com o algoritmo Ordenação por Amostragem. 
Em todos os casos, os testes são compostos de duas partes: geração da carga de dados, seguida da ordenação. %A seguir são discutidos os testes.


\subsection{Testes com benchmarks: TeraSort e Sort}

Os \textit{benchmarks} TeraSort e Sort foram os primeiros testes de ordenação realizados. O uso de algoritmos conhecidos e consolidados na ordenação no ambiente Hadoop permite compreender o funcionamento dos algoritmos e do ambiente dos testes.

\subsubsection{Terasort}
%
%This package consists of 3 map/reduce applications for Hadoop to compete in the annual terabyte sort competition.
%
%    * TeraGen is a map/reduce program to generate the data.
%    * TeraSort samples the input data and uses map/reduce to sort the data into a total order.
%    * TeraValidate is a map/reduce program that validates the output is sorted. 

O TeraSort consiste de três algoritmos, que são responsáveis pela geração dos dados, ordenação e validação. 

A geração dos dados é feita pelo algoritmo TeraGen. Os registros gerados têm um formato específico, descrito na Figura \ref{fig:formato-teragen} (incluir figura!). O registro é formado por uma chave, um id e um valor.

\begin{description}
 \item[Chave] as chaves são caracteres aleatórios do conjunto ' ' .. '~'.
 \item[Id] um valor inteiro
 \item[Valor] consiste de 70 caracteres de 'A' a 'Z'. 
 \end{description}

O número de registros gerados é um parâmetro definido pelo usuário, e os dados gerados são dividos em dois arquivos. Nos testes realizados, foram gerados dois arquivos, cada um contendo 50 mil linhas. 

O TeraSort lê tais arquivos e realiza a ordenação. Após a ordenação, os dados são validados pelo TeraValidade. Caso haja algum erro na ordenação, o algoritmo escreve um arquivo informando quais foram as chaves com erros. 



% TeraGen generates output data that is byte for byte equivalent to the C version including the newlines and specific keys. It divides the desired number of rows by the desired number of tasks and assigns ranges of rows to each map. The map jumps the random number generator to the correct value for the first row and generates the following rows.
% 
% TeraSort is a standard map/reduce sort, except for a custom partitioner that uses a sorted list of N-1 sampled keys that define the key range for each reduce. In particular, all keys such that sample[i-1] <= key < sample[i] are sent to reduce i. This guarantees that the output of reduce i are all less than the output of reduce i+1. To speed up the partitioning, the partitioner builds a two level trie that quickly indexes into the list of sample keys based on the first two bytes of the key. TeraSort generates the sample keys by sampling the input before the job is submitted and writing the list of keys into HDFS. The input and output format, which are used by all 3 applications, read and write the text files in the right format. The output of the reduce has replication set to 1, instead of the default 3, because the contest does not require the output data be replicated on to multiple nodes.
% 
% TeraValidate ensures that the output is globally sorted. It creates one map per a file in the output directory and each map ensures that each key is less than or equal to the previous one. The map also generates records with the first and last keys of the file and the reduce ensures that the first key of file i is greater that the last key of file i-1. Any problems are reported as output of the reduce with the keys that are out of order. 


% Rodar o terasort e obter arquivo ordenado.
% Validar a ordenação feita com o TeraValidade.
% 
% 3.1) Terasort
% Os dados utlizados para ordenação com o TeraSort foram gerados através do algoritmo TeraGen. 
% São dois arquivos de 50 mil linhas cada. (+- 10 MB)
% 

% 1.2) Sort (4 máquinas)
% Ordenar normalmente. 
% (sugestão: usar o mesmo arquivo de entrada do terasort e conferir o resultado com o do teravalidade).
% 
%
\subsubsection{Sort}

Sort é um dos \textit{benchmarks}  de ordenação de dados mais conhecidos para Hadoop. Ele é uma aplicação MapReduce, que realiza uma ordenação dos dados de entrada. Além da ordenação, é fornecido um programa padrão para geração de dados aleatórios de entrada, o RandomWriter. 

Os dados utilizados para os testes de ordenação com o Sort foram gerados pelo algoritmo RandomWriter. Para cada máquina do \textit{cluster}, são escritos 10 arquivos de 1GB cada em formato binário, totalizando 10GB.
% 


% 3.3) Ordenação por Amostragem


\subsection{Testes com o Algoritmo Ordenação por Amostragem}

(A escrever)

(GeraDados)
Programa implementado em Java para geração de chaves inteiras aleatórias.
Foram gerados 10 conjuntos de chaves entre $10^{6}$ (2MB) e  $10^{10}$ (20GB) chaves inteiras. 
Anotar os tempos de execução de cada algoritmo.

\subsubsection{Variando o conjunto de dados} 
 (4 máquinas)

Objetivo: avaliar a influência dos valores gerados aleatoriamente no desempenho do algoritmo. 
Testes com 10 conjuntos de $10^{6}$ dados. 
Para cada conjunto, executar 10 vezes com os parâmetros de balanceamento descritos anteriormente. 

\subsubsection{Variando a quantidade de dados} (4 máquinas)
 
Objetivo: avaliar a complexidade do algoritmo quando o conjunto de dados a serem ordenados aumenta.
Testes com dados de $10^{6}$ a $10^{10}$ gerados aleatoriamente.
 
 Para cada quantidade de dados, o algoritmo foi executado três vezes com os parâmetros descritos anteriormente. 
 
\subsubsection{Variando a quantidade de máquinas}
 (2 a 5 máquinas)
 
 Objetivo: avaliar a escalabilidade do algoritmo (diminuição do tempo de ordenação) 
 Testes com o mesmo conjunto de $10^{8}$ dados em diferentes quantidades de máquinas, de 2 a 5. 
 
 Para cada quantidade de máquinas, o algoritmo foi executado três vezes, com os parâmetros de balanceamento descritos anteriormente.
 
\subsubsection{Parâmetros do algortimo}

Frequência:
Número max de amostras: 10 mil
Núm max de partições: 	4 (5 máquinas)
			6 (5 máquinas)
			8 (5 máquinas)
			10 (5 máquinas)



\section{Cronograma de trabalho}


O cronograma de trabalho inclui as atividades que devem ser realizadas e como elas devem ser alocadas durante as disciplinas TCC I e TCC II para que o projeto possa ser concluído com sucesso.
As tarefas a serem desenvolvidas estão descritas a seguir:

\begin{num_enum}
 \item \label{c1} Pesquisa bibliográfica sobre o tema do projeto e escrita da proposta
 \item \label{c2} Estudo mais detalhado dos algoritmos de ordenação paralela,  modelo MapReduce e Hadoop.
 \item \label{c3} Configuração do ambiente Hadoop no laboratório.
 \item \label{c4} Implementação e testes.
 \item \label{c5} Escrita, revisão e entrega do relatório. 
 \item \label{c7} Análise comparativa entre os resultados.
 \item \label{c8} Escrita e revisão do projeto final.
 \item \label{c9} Entrega e apresentação.
 \end{num_enum}
 
 
Na Tabela \ref{tab:cronograma} está descrito o cronograma esperado para o desenvolvimento do projeto. Cada atividade foi alocada para se adequar da melhor maneira ao tempo disponível, mas é possível que o cronograma seja refinado posteriormente, com a inclusão de novas atividades ou redistribuição das tarefas existentes. 

\begin{table}[h]

\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{3pt}
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c |}
\hline

Atividade &Fev &Mar &Abr &Mai &Jun &Jul &Ago &Set &Out &Nov \\ \hline \hline
\ref{c1}   &$\bullet$ &$\bullet$ & & & & & & & & \\ \hline
\ref{c2}   & &$\bullet$ &$\bullet$ & & & & & & & \\ \hline
\ref{c3}   & & &$\bullet$ & & & & & & & \\ \hline
\ref{c4}   & & &$\bullet$ &$\bullet$ & &$\bullet$ &$\bullet$ & & & \\ \hline
\ref{c5}   & & & &$\bullet$ &$\bullet$ & & & & & \\ \hline
\ref{c7}   & & & & & & & &$\bullet$ & & \\ \hline
\ref{c8}   & & & & & & & & &$\bullet$ & \\ \hline
\ref{c9}   & & & & & & & & & &$\bullet$ \\ 
\hline
\end{tabular}
\end{center}
\caption{Cronograma proposto para o projeto}
\label{tab:cronograma}
\end{table}