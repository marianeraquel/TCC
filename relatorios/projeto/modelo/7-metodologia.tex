\chapter{Desenvolvimento}
\label{cap:desenvolvimento}

\section{Metodologia}

A primeira fase do projeto foi destinada ao estudo mais detalhado da computação paralela, em especial dos algoritmos de ordenação paralela, do modelo MapReduce e da plataforma Hadoop. Foram realizados testes de ordenação com os \textit{benchmarks} TeraSort e Sort, e com os exemplos disponibilizados pelo Hadoop. Após esses testes, foram realizados testes com o algoritmo Ordenação por Amostragem do trabalho de Pinhão (2011), mas com com a inclusão das distribuições Normal e Pareto. O passo seguinte foi conhecer detalhadamente o algoritmo paralelo a ser implementado. No próximo semestre serão definidas as estratégias para sua implementação em ambiente Hadoop e realizados os testes. 

O algoritmo implementado deve ser cuidadosamente avaliado para verificar um funcionamento adequado com diferentes entradas e número de máquinas. Dessa forma, foram realizados experimentos para testes de desempenho dos algoritmos com relação à quantidade de máquinas, quantidade de dados e conjunto de dados.  Os resultados obtidos foram analisados a fim de permitir comparar a desempenho dos algoritmos em cada situação. 
 

\section{Infraestrutura}

A infraestrutura necessária ao desenvolvimento do projeto foi fornecida pelo Laboratório de Redes e Sistemas (LABORES) do Departamento de Computação (DECOM). O laboratório possui um \textit{cluster} formado por cinco máquinas Dell Optiplex 380, que foram utilizados na realização dos testes dos algoritmos. Os algoritmos serão desenvolvidos em linguagem Java, de acordo com o modelo MapReduce, no ambiente Hadoop. 

Cada máquina do \textit{cluster} apresenta as seguintes características:
\begin{packed_enum}
\item Processador Intel Core 2 Duo de 3.0 GHz
\item Disco rígido SATA de 500 GB 7200 RPM
\item Memória RAM de 4 GB
\item Placa de rede Gigabit Ethernet
\item Sistema operacional Linux Ubunbu 10.04 32 bits %(kernel 2.6.\textbf{XX})
\item Sun Java JDK 1.6.0 19.0-b09 
\item Apache Hadoop 1.0.2
\end{packed_enum}


\section{Descrição dos experimentos}

A primeira parte dos experimentos consitiu em reproduzir os resultados já encontrados no trabalho de referência: testes de ordenação com os \textit{benchmarks} TeraSort e Sort, e com o algoritmo Ordenação por Amostragem. 
Em todos os casos, os testes foram compostos de duas partes: geração da carga de dados e ordenação. 

\subsection{Benchmarks: TeraSort e Sort}

Os \textit{benchmarks} TeraSort e Sort foram os primeiros testes de ordenação realizados. O uso de algoritmos conhecidos e consolidados na ordenação no ambiente Hadoop permitiu compreender o funcionamento dos algoritmos e do ambiente dos testes.

\subsubsection{Terasort}

O TeraSort consiste de três algoritmos, que são responsáveis pela geração dos dados, ordenação e validação. 
A geração dos dados é feita pelo algoritmo TeraGen. O TeraSort lê os arquivos gerados e realiza a ordenação. Após a ordenação, os dados são validados pelo TeraValidade. Caso haja algum erro na ordenação, o algoritmo escreve um arquivo informando quais foram as chaves com erros.  

\subsubsection{Sort}

Sort é um dos \textit{benchmarks}  de ordenação de dados mais conhecidos para Hadoop. Ele é uma aplicação MapReduce, que realiza uma ordenação dos dados de entrada. Além da ordenação, é fornecido um programa padrão para geração de dados aleatórios de entrada, o RandomWriter. 
Os dados utilizados para os testes de ordenação com o Sort foram gerados pelo algoritmo RandomWriter. Para cada máquina do \textit{cluster}, são escritos 10 arquivos de 1GB cada em formato binário, totalizando 10GB.


\subsection{Ordenação por Amostragem}

Para o algoritmo ordenação por amostragem foram feitos três tipos de experimentos, com alterações no número de arquivos ou máquinas. O primeiro experimento manteve constante o tamanho do arquivo a ser ordenado e o número de máquinas utilizadas na ordenação. O segundo experimento manteve constante o número de máquinas utilizadas e variou o tamanho do arquivo a ser ordenado. E o terceiro experimento manteve constante o número de dados e alterou a quantidade de máquinas utilizadas. 

Cada um dos experimentos foi realizado com três distribuições diferentes: uniforme, normal e pareto. As distribuições foram geradas por um programa implementado em Java para geração de chaves aleatórias de ponto flutuante, contendo entre $10^{6}$ (12MB) e  $10^{10}$ (120GB) chaves. 

É parte fundamental do algoritmo de Ordenação por Amostragem a definição de parâmetros que resultem em partições balanceadas. Nos testes realizados, os parâmetros definidos foram a frequência máxima de amostras e o número de partições para cada caso.  A frequência das amostras foi fixada 10 mil, e o número de partições foi função do número de máquinas utilizadas e núcleos dos processadores: 
			4 (2 máquinas); 
			6 (3 máquinas); 
			8 (4 máquinas); 
			10 (5 máquinas).


\subsubsection{Quantidade de máquinas e dados constante} 

Os testes foram realizados em 4 máquinas, com arquivos de $10^{6}$ chaves. Foram feitos testes com 10 conjuntos de dados diferentes, e para cada conjunto, o algoritmo foi executado 10 vezes, com os parâmetros de balanceamento descritos anteriormente.  O objetivo era avaliar a influência dos valores gerados aleatoriamente no desempenho do algoritmo. 

\subsubsection{Variando a quantidade de dados}
 
 Os testes variando a quantidade de dados também foram executados em 4 máquinas, com conjuntos de dados das três distribuições diferentes. Cada distribuição gerou aleatoriamente uma quantidade de dados entre $10^{6}$ e $10^{10}$. O algoritmo foi executado três vezes em cada conjunto com os parâmetros descritos anteriormente. O objetivo foi avaliar a complexidade do algoritmo quando o conjunto de dados a serem ordenados aumenta.
 
\subsubsection{Variando a quantidade de máquinas}

Esses testes foram executados com tamanho constante do arquivo de entrada  ($10^{8}$ chaves) em quantidades de máquinas que variaram de 2 a 5. 
Para cada quantidade de máquinas, foram gerados conjuntos com as distribuições diferentes e o algoritmo foi executado três vezes para cada conjunto, com os parâmetros de balanceamento descritos anteriormente. O objetivo foi avaliar a escalabilidade do algoritmo, com diminuição do tempo de ordenação quando se aumenta o número de máquinas.

\section{Cronograma de trabalho}


O cronograma de trabalho inclui as atividades que devem ser realizadas e como elas devem ser alocadas durante as disciplinas TCC I e TCC II para que o projeto possa ser concluído com sucesso.
As tarefas a serem desenvolvidas estão descritas a seguir:

\begin{num_enum}
 \item \label{c1} Pesquisa bibliográfica sobre o tema do projeto e escrita da proposta.
 \item \label{c2} Estudo mais detalhado dos algoritmos de ordenação paralela,  modelo MapReduce e Hadoop.
 \item \label{c3} Configuração do ambiente Hadoop no laboratório.
 \item \label{c4} Implementação e testes.
 \item \label{c5} Escrita, revisão e entrega do relatório. 
 \item \label{c7} Análise comparativa entre os resultados.
 \item \label{c8} Escrita e revisão do projeto final.
 \item \label{c9} Entrega e apresentação.
 \end{num_enum}
 
 
Na Tabela \ref{tab:cronograma} está descrito o cronograma esperado para o desenvolvimento do projeto. Cada atividade foi alocada para se adequar da melhor maneira ao tempo disponível, mas é possível que o cronograma seja refinado posteriormente, com a inclusão de novas atividades ou redistribuição das tarefas existentes. 

\begin{table}[h]

\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{3pt}
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c |}
\hline

Atividade &Fev &Mar &Abr &Mai &Jun &Jul &Ago &Set &Out &Nov \\ \hline \hline
\ref{c1}   &$\bullet$ &$\bullet$ & & & & & & & & \\ \hline
\ref{c2}   & &$\bullet$ &$\bullet$ & & & & & & & \\ \hline
\ref{c3}   & & &$\bullet$ & & & & & & & \\ \hline
\ref{c4}   & & &$\bullet$ &$\bullet$ & &$\bullet$ &$\bullet$ & & & \\ \hline
\ref{c5}   & & & &$\bullet$ &$\bullet$ & & & & & \\ \hline
\ref{c7}   & & & & & & & &$\bullet$ & & \\ \hline
\ref{c8}   & & & & & & & & &$\bullet$ & \\ \hline
\ref{c9}   & & & & & & & & & &$\bullet$ \\ 
\hline
\end{tabular}
\end{center}
\caption{Cronograma proposto para o projeto}
\label{tab:cronograma}
\end{table}
