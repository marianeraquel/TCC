\chapter{Desenvolvimento}
\label{cap:desenvolvimento}

\section{Metodologia}

A primeira fase do projeto será destinada ao estudo mais detalhado da computação paralela, em especial os algoritmos de ordenação paralela, dos fatores que influenciam o desempenho de tais algoritmos, o modelo MapReduce e a plataforma Hadoop. O passo seguinte é conhecer detalhadamente o algoritmo paralelo a ser implementado e definir as estratégias para sua implentação ambiente Hadoop. 
O algoritmo implementado deve ser cuidadosamente avaliado para verificar um funcionamento adequado com diferentes entradas e número de máquinas. 

Em seguida, serão realizados experimentos para testes de desempenho dos algoritmos com relação à quantidade de máquinas, quantidade de dados e conjunto de dados.  Os resultados obtidos serão analisados e permitirão comparar a desempenho dos algoritmos em cada situação. 


\section{Infraestrutura}

A infra estrutura necessária ao desenvolvimento do projeto será fornecida pelo Laboratório de Redes e Sistemas (LABORES) do Departamento de Computação (DECOM). O laboratório possui um \textit{cluster} formado por cinco máquinas Dell Optiplex 380, que serão utilizadas na realização dos testes dos algoritmos. Os algoritmos serão desenvolvidos em linguagem Java, de acordo com o modelo MapReduce, no ambiente Hadoop. 

Cada máquina do \textit{cluster} apresenta as seguintes características:
\begin{packed_enum}
\item Processador Intel Core 2 Duo de 3.0 GHz
\item Disco rígido SATA de 500 GB 7200 RPM
\item Memória RAM de 4 GB
\item Placa de rede Gigabit Ethernet
\item Sistema operacional Linux Ubunbu 10.04 32 bits %(kernel 2.6.\textbf{XX})
\item Sun Java JDK 1.6.0 19.0-b09 
\item Apache Hadoop 1.0.2
\end{packed_enum}


\section{Descrição dos experimentos}

A primeira parte dos experimentos consitiu em reproduzir os resultados já encontrados no trabalho de referência: testes de ordenação com os \textit{benchmarks} TeraSort e Sort, e com o algoritmo Ordenação por Amostragem. 
Em todos os casos, os testes são compostos de duas partes: geração da carga de dados, seguida da ordenação. 

\subsection{Benchmarks: TeraSort e Sort}

Os \textit{benchmarks} TeraSort e Sort foram os primeiros testes de ordenação realizados. O uso de algoritmos conhecidos e consolidados na ordenação no ambiente Hadoop permite compreender o funcionamento dos algoritmos e do ambiente dos testes.

\subsubsection{Terasort}

O TeraSort consiste de três algoritmos, que são responsáveis pela geração dos dados, ordenação e validação. 
A geração dos dados é feita pelo algoritmo TeraGen. Os registros gerados têm um formato específico, formado por uma chave, um id e um valor. As  chaves são caracteres aleatórios do conjunto ' ' .. '~'. O id é um valor inteiro que representa a linha, e o valor consiste de 70 caracteres de 'A' a 'Z'. 

O número de registros gerados é um parâmetro definido pelo usuário, e os dados gerados são dividos em dois arquivos. Nos testes realizados, foram gerados dois arquivos, cada um contendo 50 mil linhas. 

O TeraSort lê tais arquivos e realiza a ordenação. Após a ordenação, os dados são validados pelo TeraValidade. Caso haja algum erro na ordenação, o algoritmo escreve um arquivo informando quais foram as chaves com erros. 


\subsubsection{Sort}

Sort é um dos \textit{benchmarks}  de ordenação de dados mais conhecidos para Hadoop. Ele é uma aplicação MapReduce, que realiza uma ordenação dos dados de entrada. Além da ordenação, é fornecido um programa padrão para geração de dados aleatórios de entrada, o RandomWriter. 

Os dados utilizados para os testes de ordenação com o Sort foram gerados pelo algoritmo RandomWriter. Para cada máquina do \textit{cluster}, são escritos 10 arquivos de 1GB cada em formato binário, totalizando 10GB.
% 


% 3.3) Ordenação por Amostragem


\subsection{Ordenação por Amostragem}

Para o algoritmo ordenação por amostragem foram feitos três tipos de experimentos diferentes, com alterações no número de arquivos ou máquinas. O primeiro experimento manteve constante o tamanho do arquivo a ser ordenado e o número de máquinas utilizadas na ordenação. O segundo experimento manteve constante o número de máquinas utilizadas e variou o tamanho do arquivo a ser ordenado. O terceiro experimento manteve constante o número de dados e alterou a quantidade de máquinas utilizadas. 

Cada um dos testes é 

(GeraDados)
Programa implementado em Java para geração de chaves inteiras aleatórias.
Foram gerados 10 conjuntos de chaves entre $10^{6}$ (12MB) e  $10^{10}$ (120GB) chaves inteiras. 
Anotar os tempos de execução de cada algoritmo.

\subsubsection{Variando o conjunto de dados} 
 (4 máquinas)

Objetivo: avaliar a influência dos valores gerados aleatoriamente no desempenho do algoritmo. 
Testes com 10 conjuntos de $10^{6}$ dados. 
Para cada conjunto, executar 10 vezes com os parâmetros de balanceamento descritos anteriormente. 

\subsubsection{Variando a quantidade de dados} (4 máquinas)
 
Objetivo: avaliar a complexidade do algoritmo quando o conjunto de dados a serem ordenados aumenta.
Testes com dados de $10^{6}$ a $10^{10}$ gerados aleatoriamente.
 
 Para cada quantidade de dados, o algoritmo foi executado três vezes com os parâmetros descritos anteriormente. 
 
\subsubsection{Variando a quantidade de máquinas}
 (2 a 5 máquinas)
 
 Objetivo: avaliar a escalabilidade do algoritmo (diminuição do tempo de ordenação) 
 Testes com o mesmo conjunto de $10^{8}$ dados em diferentes quantidades de máquinas, de 2 a 5. 
 
 Para cada quantidade de máquinas, o algoritmo foi executado três vezes, com os parâmetros de balanceamento descritos anteriormente.
 
\subsubsection{Parâmetros do algortimo}

Frequência:
Número max de amostras: 10 mil
Núm max de partições: 	4 (5 máquinas)
			6 (5 máquinas)
			8 (5 máquinas)
			10 (5 máquinas)



\section{Cronograma de trabalho}


O cronograma de trabalho inclui as atividades que devem ser realizadas e como elas devem ser alocadas durante as disciplinas TCC I e TCC II para que o projeto possa ser concluído com sucesso.
As tarefas a serem desenvolvidas estão descritas a seguir:

\begin{num_enum}
 \item \label{c1} Pesquisa bibliográfica sobre o tema do projeto e escrita da proposta
 \item \label{c2} Estudo mais detalhado dos algoritmos de ordenação paralela,  modelo MapReduce e Hadoop.
 \item \label{c3} Configuração do ambiente Hadoop no laboratório.
 \item \label{c4} Implementação e testes.
 \item \label{c5} Escrita, revisão e entrega do relatório. 
 \item \label{c7} Análise comparativa entre os resultados.
 \item \label{c8} Escrita e revisão do projeto final.
 \item \label{c9} Entrega e apresentação.
 \end{num_enum}
 
 
Na Tabela \ref{tab:cronograma} está descrito o cronograma esperado para o desenvolvimento do projeto. Cada atividade foi alocada para se adequar da melhor maneira ao tempo disponível, mas é possível que o cronograma seja refinado posteriormente, com a inclusão de novas atividades ou redistribuição das tarefas existentes. 

\begin{table}[h]

\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{3pt}
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c |}
\hline

Atividade &Fev &Mar &Abr &Mai &Jun &Jul &Ago &Set &Out &Nov \\ \hline \hline
\ref{c1}   &$\bullet$ &$\bullet$ & & & & & & & & \\ \hline
\ref{c2}   & &$\bullet$ &$\bullet$ & & & & & & & \\ \hline
\ref{c3}   & & &$\bullet$ & & & & & & & \\ \hline
\ref{c4}   & & &$\bullet$ &$\bullet$ & &$\bullet$ &$\bullet$ & & & \\ \hline
\ref{c5}   & & & &$\bullet$ &$\bullet$ & & & & & \\ \hline
\ref{c7}   & & & & & & & &$\bullet$ & & \\ \hline
\ref{c8}   & & & & & & & & &$\bullet$ & \\ \hline
\ref{c9}   & & & & & & & & & &$\bullet$ \\ 
\hline
\end{tabular}
\end{center}
\caption{Cronograma proposto para o projeto}
\label{tab:cronograma}
\end{table}