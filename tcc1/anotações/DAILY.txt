10/04
Primeiros testes com Hadoop no laboratório.
Criei usuário marianehadoop no ametista.
É preciso usar o su - hadoop para fazer as execuções de acordo com o tutorial.
10.17.20.81 diamante
10.17.20.88 esmeralda		
10.17.20.87 rubi		
10.17.20.86 quartzo			
10.17.20.85 turmalina		
10.17.20.84 turquesa	(03)	
10.17.20.82 ametista	
10.17.20.83 granada


como iniciar um teste

A) Preparar o ambiente
SLAVES=turmalina
1- logar 				su - hadoop
2- pasta do hadoop 			cd /usr/local/hadoop/
3- verificar hosts no arquivo 		vi conf/core-site.xml (colocar nos arquivos dos slaves endereço/porta do master)
3.1-incluir o número de hosts a duplicar os arquivos	vi conf/hsfs-site.xml
(The default value of dfs.replication is 3. However, we have only two nodes available, so we set dfs.replication to 2.)
4- parar todos os serviços ativos	bin/stop-all.sh
5- verificar as conexões		ssh localhost e ssh SLAVES
6- iniciar os serviços do hadoop
6.1- iniciar HDFS 			bin/start-dfs.sh
(nameNode master e dataNode nos slaves)
6.2- iniciar MapReduce			bin/start-mapred.sh
7- verificar master			jps e tailf logs/hadoop-hadoop-datanode-ametista.log 
8- verificar slave			jps e tailf logs/hadoop-hadoop-datanode-SLAVES.log
9- paineis do hadoop			http://localhost:50030/jobtracker.jsp
					http://localhost:50070/dfshealth.jsp

B) Execução
1- copiar arquivos que serão testado para o dfs
bin/hadoop dfs -copyFromLocal /home/marianehadoop/clusterdata/wordcount/ /user/marianehadoop/wordcount

2- run
bin/hadoop jar hadoop*examples*.jar wordcount /user/marianehadoop/wordcount /user/marianehadoop/wordcount-output

3- se quiser copiar os resultados
bin/hadoop dfs -getmerge /user/marianehadoop/wordcount-output /home/marianehadoop/clusterdata/wordcount/

16/04
Início da escrita da seção de forças que influenciam os algoritmos paralelos.
Devo escrever uma seção explicando que todos algoritmos paralelos funcionam de maneira similar. 

17/04
Testes no laboratório. 
Algoritmos executando no cluster. Evandro ajudou a alterar os parâmetros nos slaves para que seja possível rodar em cluster. 
As execuções ocorreram com sucesso para PI e WordCount.


07/05
Volta dos testes no laboratório.
Execução dos algoritmos de ordenação.
Algoritmos não conseguiram ser executados com sucesso em várias máquinas.
Problemas com o ssh
A solução é adicionar no mestre os slaves
ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@slave

12/05
Instalado com sucesso novo opensuse (12.1). Hadoop e netbeans funcionando corretamente.
É possível utilizar o netbeans para codificar e gerar o jar. É preciso apenas criar o projeto e incluir as bibliotecas do hadoop. \o/
O comando clean and build cria o jar corretamente para execução no ambiente hadoop em cluster. 

Para facilitar a compreensão e uso posterior, cada projeto inclui um arquivo chamado run, que mostra todos os passos para executar o arquivo em um ambiente configurado. 
As configurações devem ser escritas e deixadas em um arquivo a parte, junto com os demais comandos considerados uteis. 

13/5
Foram feitos testes com o GeraDados e OrdenacaoPorAmostragem.
É preciso verificar quais são todos os testes que devem ser feitos, e como devem ser feitos. 
Escrever sobre tais testes, função map, reduce, e responder email paula. 

14/5

Testes com TeraSort nas máquinas ametista e turquesa.
Configuração para utilizar o hadoop na máquina quartzo.

Três resultados escritos em RESULTADOS.xls.

15/5
Testes 1.1.
Uso do TeraSort na máquina quartzo.
Resultados escritos nos arquivos. Média de 10 execuções com tempo compatível.

16/5 
Testes 1.2.
Inicio dos testes com o Sort.

18/5 
Testes 1.2
Testes com Sort em 4 máquinas. 
Tempos de ordenação dentro do esperado. 

21/5
Testes 2 Ordenação por amostragem
2.1) Variando o conjunto de dados (4 máquinas)

Gerar 10 conjuntos aleatórios com GeraDados de tamanho 10⁶.
Executar 10 vezes a ordenação por amostragem para cada conjunto.

22/5 a 26/5 
Outros alunos executando testes. Indisponibilidade de máquinas.


28/5

Execução?

