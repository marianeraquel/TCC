10/04
Primeiros testes com Hadoop no laboratório.
Criei usuário marianehadoop no ametista.
É preciso usar o su - hadoop para fazer as execuções de acordo com o tutorial.
10.17.20.81 diamante
10.17.20.88 esmeralda		
10.17.20.87 rubi		
10.17.20.86 quartzo			
10.17.20.85 turmalina		
10.17.20.84 turquesa	(03)	
10.17.20.82 ametista	
10.17.20.83 granada


como iniciar um teste

A) Preparar o ambiente
SLAVES=turmalina
1- logar 				su - hadoop
2- pasta do hadoop 			cd /usr/local/hadoop/
3- verificar hosts no arquivo 		vi conf/core-site.xml (colocar nos arquivos dos slaves endereço/porta do master)
3.1-incluir o número de hosts a duplicar os arquivos	vi conf/hsfs-site.xml
(The default value of dfs.replication is 3. However, we have only two nodes available, so we set dfs.replication to 2.)
4- parar todos os serviços ativos	bin/stop-all.sh
5- verificar as conexões		ssh localhost e ssh SLAVES
6- iniciar os serviços do hadoop
6.1- iniciar HDFS 			bin/start-dfs.sh
(nameNode master e dataNode nos slaves)
6.2- iniciar MapReduce			bin/start-mapred.sh
7- verificar master			jps e tailf logs/hadoop-hadoop-datanode-ametista.log 
8- verificar slave			jps e tailf logs/hadoop-hadoop-datanode-SLAVES.log
9- paineis do hadoop			http://localhost:50030/jobtracker.jsp
					http://localhost:50070/dfshealth.jsp

B) Execução
1- copiar arquivos que serão testado para o dfs
bin/hadoop dfs -copyFromLocal /home/marianehadoop/clusterdata/wordcount/ /user/marianehadoop/wordcount

2- run
bin/hadoop jar hadoop*examples*.jar wordcount /user/marianehadoop/wordcount /user/marianehadoop/wordcount-output

3- se quiser copiar os resultados
bin/hadoop dfs -getmerge /user/marianehadoop/wordcount-output /home/marianehadoop/clusterdata/wordcount/

16/04
Início da escrita da seção de forças que influenciam os algoritmos paralelos.
Devo escrever uma seção explicando que todos algoritmos paralelos funcionam de maneira similar. 

17/04
Testes no laboratório. 
