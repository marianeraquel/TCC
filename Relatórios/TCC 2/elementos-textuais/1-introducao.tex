%
% Documento: Introdução
%

\chapter{Introdução}\label{chap:introducao}

Esse capítulo apresenta o contexto da computação que torna relevante o estudo e a comparação de algoritmos de ordenação paralela no modelo MapReduce, sobretudo na implementação Hadoop; o crescimento de dados que contribuiu para a necessidade de mudança da computação sequencial para a computação paralela e a importância dos algoritmos de ordenação, utilizados em diversas aplicações. Adicionalmente, busca delimitar o tema a ser tratado, os objetivos do trabalho e sua estrutura de capítulos.  


\section{Caracterização do Problema}
\label{sec:caracProblema}

Na última década, a quantidade de dados  disponível na web, gerada e processada por empresas e sistemas computacionais, aumentou várias ordens de grandeza, fazendo do processamento dos dados um desafio para a computação sequencial. Como resultado, torna-se crucial substituir a computação tradicional pela computação distribuída eficiente \cite{Lin:2010}. A mudança no modelo de programação sequencial para paralelo é um fato inevitável e ocorre gradualmente, desde que a indústria declarou que seu futuro está em computação paralela \cite{Asanovic:2009}.

A ordenação é um dos problemas fundamentais da ciência da computação e um dos problemas algorítmicos mais estudados. Suas aplicações vão desde sistemas de banco de dados à computação gráfica, além de muitos outros algoritmos que podem ser descritos em termos de ordenação \cite{Satish:2009,Amato:1996}.  Muitas aplicações dependem de ordenações eficientes como base para seu próprio desempenho, que podem ser desenvolvidas através de rotinas eficientes de ordenação em arquiteturas paralelas e distribuídas. 
O uso crescente de computação paralela em sistemas computacionais gera a necessidade de algoritmos de ordenação inovadores, desenvolvidos para dar suporte a essas aplicações. 
 

Com a constante evolução das arquiteturas de computadores há uma necessidade contínua de explorar técnicas de ordenação em arquiteturas emergentes. 
Nesse sentido, são desenvolvidos diferentes modelos de programação paralela para ambientes \textit{multicore} e distribuído, como o MapReduce. O MapReduce é um modelo de programação paralela desenvolvido pela Google para processamento de grandes volumes de dados distribuídos em \textit{clusters} \cite{Dean:2008}. Esse modelo propõe simplificar a computação paralela, escondendo  do desenvolvedor os detalhes da paralelização e utilizando duas funções principais - Map e Reduce.
Uma das implementações mais conhecidas e utilizadas do modelo é o Hadoop \cite{White:2009}, ferramenta de código aberto, desenvolvida por Doug Cutting em 2005 e apoiada pela Yahoo!. 



O trabalho proposto por %\citeonline{Paula:2011} 
Pinhão (2011) apresentou uma avaliação da escalabilidade 
%- habilidade de um sistema manipular uma porção crescente de trabalho de forma uniforme - 
de algoritmos de ordenação paralela no modelo MapReduce. Para tal, foi desenvolvido o algoritmo de Ordenação por Amostragem, no ambiente Hadoop, e seu desempenho foi avaliado em relação à quantidade de dados de entrada e ao número de máquinas utilizadas. 

Considerando esse contexto, o presente trabalho segue o tema e busca continuar o estudo com a implementação e análise de escalabilidade, em relação à quantidade de dados a ser ordenada e de número de máquinas utilizadas, do algoritmo \textit{Quicksort} Paralelo, no modelo MapReduce e ambiente Hadoop. Outro ponto é a comparação do desempenho dos dois algoritmos - Ordenação por Amostragem e \textit{Quicksort} Paralelo - em diferentes cenários.


\section{Motivação}
\label{sec:motivacao}


% 1. crescimento dos dados requer mais poder computacional

O volume de dados que é produzido e tratado diariamente em indústrias, empresas e até mesmo em âmbito pessoal teve um rápido crescimento nos últimos anos, tornando o desenvolvimento de soluções capazes de lidar com tais volumes de dados uma das grandes preocupações atuais. Estima-se que dados não estruturados são a maior porção e a de mais rápido crescimento dentro das empresas. 
%, tendo em vista a quantidade de dados processados , e o  desse volume de dados.
Não é fácil medir o volume total de dados armazenados digitalmente, mas uma estimativa da \textit{International Data Corporation} (IDC) calculou o tamanho do universo digital em 0,18 zettabytes em 2006, prevendo um crescimento de dez vezes até 2011, chegando a 1,8 zettabytes \cite{Gantz:2008}.
Em 2008, o Facebook armazenava aproximadamente 10 bilhões de fotos, que ocupavam mais de um petabyte. \textit{The Internet Archive} armazenava aproximadamente 2 petabytes de dados, com acréscimo de 20 terabytes por mês e a Bolsa de Valores de Nova Iorque gerava cerca de um terabyte de novos dados comerciais por dia
\cite{White:2009}. %, o que torna o processamento de tal volume de dados muitas vezes inviável.

%2. mais poder computacional pode ser conseguido com a) clock  e b) paralelismo

Mesmo para os computadores atuais, é um desafio conseguir lidar com quantidades de dados tão grandes. É preciso buscar soluções escaláveis, que apresentem bom desempenho mesmo com aumento significativo no número de recursos e na carga de trabalho. 
%3. a indústria sabe que agora só é possível trabalhar o paralelismo
Nos últimos 40 anos, o aumento do poder computacional deveu-se, largamente, ao aumento da capacidade do hardware. Atualmente, o limite físico da velocidade do processador foi alcançado e arquitetos sabem que o aumento no desempenho só pode ser alcançado com o uso de computação paralela. Com isso, a indústria têm recorrido cada vez mais a arquiteturas paralelas para continuar a fazer progressos \cite{Manferdelli:2008}. 

As tendências atuais estão redirecionando o foco da computação, do tradicional modelo de processamento científico para o processamento de grandes volumes de dados.
Nesse sentido, arquiteturas paralelas, como as de memória distribuída, estão cada vez mais frequentes, suprindo a necessidade de uma computação distribuída eficiente, que forneça alto desempenho no processamento de dados \cite{Bryant:2011}.
%substituir a computação sequencial 
%.por, cujo foco sejam os dados e . 


% 4. computação paralela é dificil

As técnicas tradicionais de programação paralela - como passagem de mensagens e memória compartilhada - em geral são complexas e de difícil entendimento para grande parte dos desenvolvedores. Em tais modelos é preciso gerenciar localidades temporais e espaciais; lidar explicitamente com concorrência, criando e sincronizando \textit{threads} através de mensagens e semáforos. Dessa forma, não é uma tarefa simples escrever códigos paralelos corretos e escaláveis para algoritmos não triviais \cite{Breshears:2009}.

% 5. com o map reduce, é possível ordenar de forma rápida e fácil

O MapReduce surgiu como uma alternativa aos modelos tradicionais, com o objetivo de simplificar a computação paralela. 
%O maior benefício desse modelo é a simplicidade. 
O foco do programador é a descrição funcional do algoritmo e não as formas de paralelização. Nos últimos anos o modelo têm se estabelecido como uma das plataformas de computação paralela mais utilizada no processamento de terabytes e petabytes de dados \cite{Ranger:2007}.
%É um caminho natural para o processamento de dados em larga escala o uso de \textit{clusters}. 
MapReduce e sua implementação código aberto Hadoop oferecem  uma alternativa economicamente atraente através de uma plataforma eficiente de computação distribuída, capaz de lidar com grandes volumes de dados e mineração de petabytes de informações não estruturadas \cite{Cherkasova:2011}.

% 6. com o crescimento dos dados no mundo, ordenar está cada vez mais complexo 
Mesmo com o grande processamento  empregado em interfaces gráficas, visualização e jogos, a ordenação continua a ser uma parte considerável da computação e estima-se que seja responsável por aproximadamente 80\% dos ciclos de processamento\cite{Ranger:2007}. O uso de algoritmos paralelos de ordenação em tais aplicações melhora o tempo de execução do algoritmo e torna viável o processamento de grande quantidades de dados.


\section{Justificativa}
\label{sec:justificativa}

Os algoritmos paralelos para ordenação têm sido objeto de estudo desde o princípio da computação paralela, uma vez que a  ordenação é um dos problemas fundamentais da ciência da computação.
Um grande número de aplicações possui uma fase de computação intensa, na qual uma lista de elementos deve ser ordenada com base em algum de seus atributos. Um exemplo é o algoritmo de Page Rank \cite{Page:1999} da Google: as páginas de resultado de uma consulta são classificadas de acordo com sua relevância, e depois precisam ser ordenadas de maneira eficiente \cite{Kale:2010}. 
 

%Presenting the results from database queries, compiling a list of business investments with associated risk-reward measures, and figuring the company payroll are all operations that require sorting.  Every time you get a list of URLs from a search engine, the results have been sorted, typically by some measure of relevance to your original query.

%\textcolor{red}{Os algoritmos ótimos existentes em arquitetura sequencial, como Quicksort e Heapsort necessitam de um tempo mínimo \textit{(n log n)} para ordenar uma sequência de \textit{n} elementos \cite{Aho:1974}}.

% 7. a ordenação paralela pode melhorar essa tarefa

Na ordenação paralela, fatores como movimentação de dados, balanço de carga, latência de comunicação e distribuição inicial das chaves são considerados ingredientes chave para o bom desempenho, e variam de acordo com o algoritmo escolhido como solução \cite{Kale:2010}.  No exemplo do Page Rank, o número de páginas a serem ordenadas é enorme, e elas são recolhidas de diversos servidores da Google, assim é uma questão fundamental escolher algoritmo paralelo com o melhor desempenho dentre as soluções possíveis.
% 8. mas algoritmos paralelos são muito dependentes de ambiente e distribuição inicial, portanto é importante avaliar o desempenho desses algoritmos
Dado o grande número de algoritmos de ordenação paralela e grande variedade de arquiteturas paralelas, é uma tarefa difícil escolher um algoritmo genérico para diferentes máquinas e instâncias do problema.

 Além disso, não existe um modelo teórico conhecido que possa ser aplicado para prever com precisão o desempenho de um algoritmo em arquiteturas diferentes \cite{Amato:1996}.
Assim, estudos experimentais assumem uma crescente importância para a avaliação e seleção de algoritmos apropriados para ambientes paralelos. É preciso que estudos sejam realizados para que determinado algoritmo possa ser recomendado em certa arquitetura com alto grau de confiança.




\section{Objetivos}
\label{sec:objetivos}

\subsection{Objetivo Geral}
\label{subsec:objetivoGeral}

Este projeto busca continuar o estudo sobre ordenação paralela desenvolvido por Pinhão (2011), com a análise de desempenho dos algoritmos de ordenação Ordenação por Amostragem e \textit{Quicksort}. No citado trabalho, foi feito um estudo sobre a computação paralela e algoritmos de ordenação no modelo MapReduce, com a implementação do algoritmo de Ordenação por Amostragem em ambiente Hadoop. 
No presente trabalho busca-se comparar os algoritmos Ordenação por Amostragem e \textit{Quicksort} Paralelo em relação à quantidade de dados a serem ordenados, variabilidade dos dados de entrada e número máquinas utilizadas. 


\subsection{Objetivos Específicos}
\label{subsec:objetivosEspecificos}

Desse modo, os objetivos deste trabalho são:

\begin{packed_enum}
\item Estudar a programação paralela aplicada a algoritmos de ordenação;
\item Implementar o algoritmo de ordenação  \textit{Quicksort} no modelo MapReduce, com o \textit{framework} Hadoop;
\item Comparar as implementações dos algoritmos de ordenação paralela: Ordenação por Amostragem e \textit{Quicksort} Paralelo em termos de desempenho.
\end{packed_enum}

\section{Organização do Texto}
\label{sec:organizacaoTexto}

Esse projeto está organizado em sete capítulos. O próximo capítulo apresenta o referencial teórico para o desenvolvimento do trabalho, com conceitos de computação paralela  e do modelo MapReduce. O Capítulo \ref{cap:ordenacao} complementa o referencial teórico e apresenta os conceitos da ordenação de dados e ordenação paralela. 
O Capítulo \ref{cap:desenvolvimento} descreve a metodologia de pesquisa, indicando os passos seguidos durante o desenvolvimento. Os resultados preliminares obtidos até a entrega do projeto são apresentados no Capítulo \ref{cap:resultados}. As conclusões e os próximos passos para a finalização do projeto estão no Capítulo \ref{cap:conclusoes}.
