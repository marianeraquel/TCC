%
% Documento: Planejamento dos Experimentos
%

\chapter{Planejamento dos Experimentos}
\label{cap:planejamentoDosExperimentos}

Esse capítulo trata dos experimentos realizados no trabalho, indicando a metodologia utilizada, a infraestrutura disponível para realização dos testes, a descrição e objetivo de cada teste proposto, as cargas de trabalho utilizadas e as métricas para avaliação do desempenho.



A primeira fase do trabalho foi destinada ao estudo mais detalhado da computação paralela, em especial dos algoritmos de ordenação paralela, do modelo MapReduce e da plataforma Hadoop. Foram executados testes com os exemplos disponíveis no código do Hadoop e com os \textit{benchmarks} \textit{TeraSort} e \textit{Sort}. 
Após esses testes, foram realizados experimentos com o algoritmo Ordenação por Amostragem, utilizando dados em distribuição uniforme, mesma carga de dados utilizada no trabalho de Pinhão (2011). Além dessa carga de dados, foram feitos testes incluindo duas novas distribuições - Normal e Pareto - que buscavam confirmar que o algoritmo mantinha o balanceamento de carga mesmo com entradas contendo dados de distribuições tão distintas. 

O passo seguinte foi conhecer detalhadamente o algoritmo paralelo a ser implementado, o \textit{Quicksort}, assim como definir as estratégias para sua implementação no ambiente Hadoop. 
Com sua implementação realizada, foram 
de diferentes configurações, diferentes entradas e número de máquinas, além de medir o desempenho dos algoritmos com relação à quantidade de máquinas, quantidade de dados e conjunto de dados. Os resultados obtidos até o momento foram analisados a fim de permitir comparar o desempenho dos algoritmos em cada situação.


\section{Descrição dos experimentos}
\label{sec:experimentos}

A primeira parte dos experimentos consistiu em reproduzir os resultados já encontrados no trabalho de referência: testes de ordenação com os \textit{benchmarks TeraSort} e \textit{Sort}, e com o algoritmo Ordenação por Amostragem. 
Em todos os casos, os testes foram compostos de duas partes: geração da carga de dados e ordenação. 

\subsection{Benchmarks: TeraSort e Sort}

%A execução dos \textit{benchmarks} TeraSort e Sort foram os primeiros testes de ordenação realizados. A importância desses testes consiste no fato dessas aplicações de ordenação serem conhecidas e consolidados no ambiente Hadoop. 
 
Para compreender o funcionamento dos algoritmos de ordenação e do ambiente Hadoop foram executados, primeiramente, testes com os \textit{benchmarks} \textit{TeraSort} e \textit{Sort}.  A importância desses testes consiste no fato de tais  aplicações serem conhecidas e consolidados no ambiente Hadoop. 
 O objetivo dos testes foi verificar se as condições do ambiente eram similares às apresentadas no trabalho de Pinhão (2011). Para tal, os parâmetros dos algoritmos e número de máquinas utilizadas foram similares. 

%\subsubsection{Terasort}

O \textit{TeraSort} consiste de três algoritmos, que são responsáveis pela geração dos dados, ordenação e validação, conforme descrito na seção \ref{sec:benchmarks}.
Os testes com o \textit{TeraSort} foram feitos em duas máquinas. Foram gerados pelo \textit{TeraGen} dois arquivos contendo 50 mil linhas cada e o algoritmo foi executado 10 vezes.

 
%A geração dos dados é feita pelo algoritmo TeraGen. O número de registros é um parâmetro definido pelo usuário, e os dados gerados são divididos em dois arquivos. O TeraSort lê os arquivos gerados e realiza a ordenação. Após a ordenação, os dados são validados pelo TeraValidade. Caso haja algum erro na ordenação, o algoritmo escreve um arquivo informando quais foram as chaves com erros.  

%\subsubsection{Sort}

%Sort é um dos \textit{benchmarks}  de ordenação de dados mais conhecidos para Hadoop. Ele é uma aplicação MapReduce, que realiza uma ordenação dos dados de entrada. Além da ordenação, é fornecido um programa padrão para geração de dados aleatórios de entrada, o RandomWriter. 

Para os testes realizados com o \textit{Sort} foram utilizados dados gerados pelo algoritmo \textit{RandomWriter}. Para cada máquina do \textit{cluster}, foram escritos 10 arquivos de 1GB cada em formato binário, totalizando 10GB. Os testes foram feitos em 4 máquinas, com 10 execuções. 


\section{Carga de Trabalho - OK}

Os dados utilizados foram números gerados aleatoriamente em três distribuições: uniforme, normal e pareto. As distribuições foram geradas por um programa implementado em Java para geração de chaves aleatórias de ponto flutuante, contendo entre $10^{6}$ (12MB) e  $10^{10}$ (120GB) chaves. 

As Figuras \ref{fig:uniforme}, \ref{fig:normal} e \ref{fig:pareto} exibem o padrão de frequência das chaves das três distribuições: uniforme, normal e pareto, respectivamente. 
Pode-se observar que as três distribuições tem padrões de comportamento bastante distintos, que se refletem nos arquivos de entrada gerados. A distribuição pareto é a única que está apresentada em escala logarítmica, para melhor visualização. 
Na distribuição uniforme cada chave tem a mesma probabilidade de aparecimento, levando a chaves igualmente distribuídas no intervalo. A distribuição normal concentra grande parte dos valores próximos à media, e distribui poucas chaves em valores mais extremos. A distribuição pareto possui uma grande concentração de chaves em valores próximos de 0, e pequena quantidade de valores mais altos, resultado em valores com baixa frequência no intervalo restante. %Isso pode ser visto pela escala logarítmica utilizada no gráfico que exibe essa distribuição.

\begin{figure}[!h]

\centering
\subfigure[Distribuição Uniforme]{\includegraphics[width=0.48\textwidth]{figuras/DistribuicaoUniforme.pdf} \label{fig:uniforme}}
\subfigure[Distribuição Normal]{\includegraphics[width=0.48\textwidth]{figuras/DistribuicaoNormal.pdf} \label{fig:normal}}
% \subfigure[Distribuição Pareto]{\includegraphics[width=0.48\textwidth]{figuras/DistribuicaoPareto.pdf} \label{fig:pareto}}
\caption{Distribuições dos dados gerados para ordenação}

\end{figure}


\section{Métricas de avaliação}

Os testes 


\subsection{Ordenação por Amostragem}

Os experimentos com o algoritmo Ordenação por Amostragem foram divididos em duas fases. A primeira fase consistiu na reprodução dos testes realizados no trabalho de referência, com o algoritmo implementado em Java, no ambiente Hadoop. A segunda fase dos experimentos consistiu em executar o algoritmo em cenários diferentes dos que já haviam sido apresentados. O objetivo de cada experimento era avaliar o algoritmo em situações diversas, confirmando sua escalabilidade e eficiência.

%Foram feitos três tipos de experimentos com o algoritmo, com alterações: (i) no número de arquivos, (ii) no número de máquinas e (iii) carga de dados. Em todos os casos utilizou-se a distribuição uniforme, similar à utilizada no trabalho de Pinhão (2011).

Os experimentos realizados nas duas fases podem ser divididos em três categorias, de acordo com as variações propostas: (i) no número de arquivos e (ii) no número de máquinas. 
O primeiro experimento manteve constante tanto o tamanho do arquivo a ser ordenado quanto o número de máquinas utilizadas na ordenação. 
O segundo experimento manteve constante o número de máquinas utilizadas e variou o tamanho do arquivo a ser ordenado. 
Já o terceiro experimento manteve constante o número de dados e alterou a quantidade de máquinas utilizadas. 

Na primeira fase, foram realizados os três experimentos, e em todos os casos utilizou-se a distribuição uniforme na geração dos dados, similar à utilizada no trabalho de Pinhão (2011). Os arquivos gerados continham entre $10^{6}$ (12MB) e  $10^{10}$ (120GB) chaves, e o número de máquinas utilizadas variou de 2 a 5.
Na segunda fase, cada um dos experimentos foi realizado com três conjuntos diferentes de dados.


Uma parte fundamental do algoritmo de Ordenação por Amostragem é a definição dos parâmetros de amostragem de chaves, para uma amostragem que resulte em partições balanceadas. Nos testes realizados, os parâmetros definidos foram o número máximo de amostras e o número de partições para cada caso.  O número máximo de amostras foi fixado em 10 mil, e o número de partições foi função do número de máquinas utilizadas e núcleos dos processadores: \mbox{$ Parti \text{\c{c}} \tilde{o}es = m\acute{a}quinas \times n\acute{u}cleos $}. Dessa forma, para as máquinas utilizadas, que contêm 2 núcleos, obtém-se: 4 partições para 2 máquinas; 6 para 3 máquinas; 8 para 4 máquinas; 10 para 5 máquinas.

A seguir são descritos os três tipos de testes realizados, especificando o número de máquinas utilizadas, o número de arquivos e o tamanho dos arquivos ordenados, assim como os objetivos de avaliação de cada teste.

\subsubsection{Testes de estabilidade}

\subsubsection{Variando o número de partições}

\subsubsection{Variando a distribuição dos dados} 

Os testes com número constante de máquinas e dados foram realizados em 4 máquinas, com arquivos de $10^{6}$ chaves. Foram feitos testes com 10 conjuntos de dados diferentes e, para cada conjunto, o algoritmo foi executado 10 vezes, com os parâmetros de balanceamento descritos anteriormente.  O objetivo foi avaliar a influência dos valores gerados aleatoriamente no desempenho do algoritmo. 


\subsubsection{Variando a quantidade de dados}
 
 Os testes variando a quantidade de dados também foram executados em 4 máquinas, com conjuntos de dados das três distribuições diferentes. Cada distribuição gerou aleatoriamente uma quantidade de dados entre $10^{6}$ e $10^{10}$. O algoritmo foi executado três vezes em cada conjunto com os parâmetros descritos anteriormente. O objetivo foi avaliar a complexidade do algoritmo quando o tamanho do conjunto de dados a ser ordenado aumenta.
 
\subsubsection{Variando a quantidade de máquinas}

Esses testes foram executados com tamanho constante do arquivo de entrada  ($10^{8}$ chaves) em quantidades de máquinas que variaram de 2 a 5. 
Para cada número de máquinas foram gerados conjuntos com as distribuições diferentes. O algoritmo foi executado três vezes para cada conjunto, com os parâmetros de balanceamento descritos anteriormente. O objetivo foi avaliar a escalabilidade do algoritmo, com diminuição do tempo de ordenação quando se aumenta o número de máquinas.


Os resultados dos testes com quantidade constante de máquinas e dados, variando a quantidade de dados e variando a quantidade de máquinas são apresentados e discutidos no Capítulo \ref{cap:resultados}.

\subsection{Validação dos resultados}

Para validar o resultado da ordenação realizada pelos algoritmos, foi desenvolvido um módulo para validação dos arquivos escritos, com função similar a do \textit{TeraValidade}. 
Essa aplicação deve ser executada após a ordenação completa, e verifica se alguma das chaves presentes no arquivo final está desordenada. O funcionamento é simples: o programa lê sequencialmente os arquivos ordenados e compara a chave atual com a anterior, e caso seja encontrado um valor fora de ordem, o programa escreve este valor no arquivo de saída. 
A execução de um programa de validação garante que o resultado da ordenação está correto, comprovando o funcionamento dos algoritmos desenvolvidos. 
Durante a realização dos testes, esse módulo era executado após a ordenação e confirmou que a execução estava correta em todos os casos testados.



\section{Ambiente de Desenvolvimento - OK}

O ambiente necessário ao desenvolvimento e execução do projeto foi fornecida pelo Laboratório de Redes e Sistemas (LABORES) do Departamento de Computação (DECOM) do Centro Federal de Educação Tecnológica de Minas Gerais. O LABORES possui um \textit{cluster} formado por cinco máquinas Dell Optiplex 380, que foram os recursos utilizados na realização dos testes de desempenho.

Cada máquina do \textit{cluster} apresenta as seguintes características:
\begin{packed_enum}
\item Processador Intel Core 2 Duo de 3.0 GHz
\item Disco rígido SATA de 500 GB 7200 RPM
\item Memória RAM de 4 GB
\item Placa de rede Gigabit Ethernet
\item Sistema operacional Ubuntu 10.04 32 bits %(kernel 2.6.\textbf{XX})
\item Sun Java JDK 1.6.0 19.0-b09 
\item Apache Hadoop 1.0.2
\end{packed_enum}


O próximo Capítulo apresenta os resultados coletados a partir da execução dos algoritmos no ambiente citado. 
