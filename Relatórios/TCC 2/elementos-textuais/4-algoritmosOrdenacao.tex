%
% Documento: Algoritmos de Ordenação
%

\chapter{Título a definir}
\label{chap:tituloadefinir}

Esse capítulo apresenta os algoritmos de ordenação paralela objetos desse trabalho: o algoritmo Ordenação por Amostragem  (\textit{Samplesort}) e o algoritmo \textit{Quicksort} Paralelo, implementados em Java no ambiente Hadoop. 

\section{Samplesort}
\label{sec:sampleSort}

Como descrito na seção \ref{sec:alg-outros} o algoritmo \textit{Samplesort} ou Ordenação por Amostragem realiza a ordenação de dados dividindo a entrada de dados em subconjuntos, e cada processador é responsável pela ordenação de um subconjunto. 
Quando implementado ambiente Hadoop, as fases Map e Reduce podem ser descritas da seguinte maneira: 
Na fase Map os arquivos de entrada são lidos e são formados os pares (chave, valor) para cada registro presente no arquivo. 
Em seguida é definido o vetor contendo as amostras. A partir desse vetor de amostras os dados são divididos em partições. O número de partições é determinado pelo número de máquinas e núcleos de processamento. 
Por meio de cache distribuído, as informações das partições são transmitidas para as máquinas participantes e os dados são particionados. Cada partição é atribuída a um processador, que executa a tarefa Reduce. 
Na fase Reduce, cada processador ordena os dados localmente. Essa ordenação é realizada pelo próprio \textit{framework}, que avalia a profundidade da árvore de recursão e escolhe entre os  algoritmos \textit{Quicksort} e \textit{Heapsort}. 
Após a ordenação local os dados são enviados para a máquina mestre, na qual são concatenados e formam o conjunto final ordenado.

A divisão dos dados de entrada em subconjuntos é feita buscando o balanceamento das partições. Para isso, é preciso determinar o número de elementos que devem ser destinados a uma certa partição, o que é feito através da amostragem das chaves do arquivo original. Essa estratégia baseia-se na análise de um subconjunto de dados  denominado amostra, ao invés de todo o conjunto, para estimar a distribuição de chaves e construir partições balanceadas.

A seleção das amostras pode ser feita através de diferentes estratégias, implementadas no \textit{framework} através de três amostradores: \textit{SplitSampler}, \textit{IntervalSampler} e \textit{RandomSampler}. O \textit{SplitSampler} seleciona os $n$ primeiros registros do arquivo para formar a amostra. O \textit{IntervalSampler} cria a amostra com a seleção de chaves em intervalos regulares no arquivo. No \textit{RandomSampler}, a amostra é constituída por chaves selecionadas aleatoriamente no conjunto. 
A melhor estratégia de amostragem depende diretamente dos dados de entrada. O \textit{SplitSampler} não é recomendado para arquivos quase ordenados, pois as chaves selecionadas serão as iniciais, que não são representativas do conjunto como um todo. Nesse caso, a melhor escolha é o \textit{IntervalSampler} pelo fato de selecionar chaves que representam melhor a distribuição do conjunto. O \textit{RandomSampler} é considerado um bom amostrador de propósito geral \cite{White:2009}, e foi o amostrador escolhido na implementação do algoritmo Ordenação por Amostragem feito por Pinhão (2011), que foi utilizado neste trabalho.

Para criar a amostra, o \textit{RandomSampler} necessita de alguns parâmetros, como a probabilidade de escolha de uma chave, o número máximo de amostras a serem selecionadas para realizar a amostragem e o número máximo de partições que podem ser utilizadas.
O número máximo de partições é determinado pelo número de núcleos disponíveis por processador e pela quantidade de máquinas, de acordo com a equação: \mbox{$ parti \text{\c{c}} \tilde{o}es = n\acute{u}cleos \times m\acute{a}quinas$}.
Após a definição das amostras, são conhecidos os intervalos compreendidos por cada partição. As informações das partições são armazenadas em um arquivo e transmitidas para as demais máquinas por meio de cache distribuído.

Nesse algoritmo, o ponto chave é dividir as partições de maneira balanceada, para que cada processador receba aproximadamente a mesma carga de dados. O balanceamento das partições é fundamental pois garante a formação de partições com tamanhos aproximados e reduz a possibilidade de que um processador esteja ocioso, enquanto outro processador está sobrecarregado, o que comprometeria o desempenho do algoritmo \cite{White:2009}.


A Figura \ref{fig:samplesort} apresenta um exemplo de como seria a execução do algoritmo implementado no Hadoop. 
Nesse exemplo, está representada a execução do algoritmo em duas máquinas com dois núcleos cada, totalizando 4 unidades de processamento. 
Primeiramente foram lidos os arquivos e formados os pares (chave, valor) (passos 1 e 2). 
 Em seguida foram amostrados 3 valores com o \textit{RandomSampler}  (passo 3) para determinar os valores presentes nas 4 partições  (passo 4). Após formadas as partições, os dados foram distribuídos para os escravos executarem a função Reduce.  
A função Reduce ordena localmente os dados  (passo 5) e o mestre agrupa todos os valores, escrevendo o arquivo final (passo 6).

\begin{figure}[htb]
\centering
%trim left, bottom, right and top
\includegraphics[trim=2cm 4cm 2cm 2cm, width=\textwidth]{figuras/Samplesort2.pdf}
\caption{Exemplo do algoritmo Ordenação Por Amostragem}
\label{fig:samplesort}
\end{figure}



\section{Quicksort Paralelo}
\label{sec:quicksortParalelo}


 
 % PARALELO
 
A versão paralela do \textit{Quicksort} utiliza pivôs para realizar o particionamento recursivo no conjunto de processadores que interagem. 
 A estratégia de dividir para conquistar é naturalmente extensível à paralelização, por isso o \textit{Quicksort} é um dos algoritmos mais promissores de ordenação paralela do ponto de vista da escalabilidade. Seu funcionamento permite que a divisão de chaves seja feita de maneira independente, e cada subdivisão seja ordenada sem necessidade de sincronismo. A questão do balanceamento de carga, fundamental ao desempenho do algoritmo é mantida pela semântica da seleção do pivô \cite{Kale:2010}. 

Inicialmente tem-se um conjunto de chaves e $p$ processadores, sendo um mestre e os demais escravos. Em seguida é feita a escolha do pivô e o mestre envia esse valor para os processadores escravos. Cada processador divide suas chaves em dois grupos: elementos maiores e elementos menores que o pivô. 
Para que  a distribuição dos conjuntos seja balanceada, são contabilizados os totais de elementos maiores e menores e com essa informação o mestre é capaz de definir o número de processadores que deve receber chaves menores e o número de processadores que deve receber chaves maiores que o pivô, além do número médio de chaves que cada processador deve receber. 

Na implementação no ambiente Hadoop, a fase Map os arquivos de entrada são lidos e são formados os pares (chave, valor) para cada registro presente no arquivo. O próximo passo é escolher o elemento pivô, que determina a divisão das partições. Com o valor do pivô, os dados são divididos em duas partições: conjunto de valores maiores que o pivô e conjunto de valores menores que o pivô. 
Cada partição formada pode ser novamente divida, com a escolha de um novo pivô e o particionamento dos dados. O número de partições que a entrada de dados deve ser dividida é um parâmetro determinado pelo usuário, e o algoritmo realiza as divisões até atingir esse valor. Após realizada a divisão, cada partição é atribuída a um processador, que executa a tarefa Reduce. 
Na fase Reduce, cada processador ordena os dados localmente, através do próprio \textit{framework}, como descrito anteriormente. 
Após a ordenação local cada arquivo possui um conjunto ordenado, e a concatenação de tais arquivos permite a obtenção de um arquivo final ordenado.

A escolha do pivô é fundamental para manter o balanceamento das partições, e consequentemente o bom desempenho do algoritmo. Existem diversas estratégias para a escolha desse valor, como a escolha aleatória, o primeiro valor do conjunto de dados, o último valor, dentre outros. Para a implementação, optou-se por escolher a mediana entre três valores do conjunto de dados. Dessa forma, são escolhidos três valores aleatoriamente e a mediana entre eles é definida como o pivô.

A seguir é descrito o algoritmo em alto nível:

\begin{algorithm}	

  	\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  	\SetKwData{Pivot}{pivo}
  	\SetKwFunction{RandomSampler}{RandomSampler}
  	
  	\SetKwBlock{Begin}{Quicksort}{end}
  	\Input{Arquivo de entrada, número de partições}
  	\Output{Arquivo ordenado}
  	\BlankLine
 	\Begin{
 		ParticaoPai $\leftarrow$ (Entrada, NumeroParticoesDesejadas, NumeroChaves) \;
		\While{ParticaoPai $\leftarrow$ Desempilha()}{
			\Pivot $\leftarrow$ \RandomSampler{} \;
			Fases MapReduce() \;
			\tcp {Calcular elementos para próximas partições}
			ParticaoMaiores.Chaves $\leftarrow$ Maiores \;
			ParticaoMenores.Chaves $\leftarrow$ Menores \;
			ParticaoMaiores.ParticoesDesejadas $\leftarrow$ ParticaoMaior.Chaves / ParticaoPai.Chaves \;
			ParticaoMenores.ParticoesDesejadas $\leftarrow$ ParticaoPai.ParticoesDesejadas - ParticaoMaior.ParticoesDesejadas \;	
			Empilha(ParticaoMaiores)\; 
			Empilha(ParticaoMenores)\;
		}
	}
	
	\BlankLine
	\BlankLine	
	\BlankLine
	
  	\SetKwBlock{Begin}{Function Map(Integer chave, String valor)}{end}
  	\Begin{
		\BlankLine
		\emph{chave: valor lido do arquivo \\
				valor: vazio}
		\BlankLine
		\eIf{chave $<$ pivo}{
			Menores $\leftarrow$ Menores + 1 \;
			Collect(chave, valor) \;			
		} {
			Maiores $\leftarrow$ Maiores + 1 \;
			Collect(chave, valor) \;
		}
	}
	
	\BlankLine
	\BlankLine
	\BlankLine
	
	\SetKwBlock{Begin}{Function Reduce(Integer chave, Iterator valores)}{end}
  	\Begin{
		\BlankLine
		\emph{chave: valor lido do arquivo \\
				valor: vazio}
		\BlankLine
		listaDePalavras $\leftarrow$ \Split(valor)\;
		\BlankLine
		\ForEach{palavra  listaDePalavras}{
	    		\Emit(palavra, 1)\;
		}
	}
	
	
	\caption{Algoritmo quicksort em MapReduce}
	\label{alg:quicksort}
\end{algorithm}


\begin{figure}[htb]
\centering
%trim left, bottom, right and top
\includegraphics[trim=2cm 9cm 2cm 2cm, width=\textwidth]{figuras/Quicksort.pdf}
\caption{Esquema do algoritmo Quicksort no modelo MapReduce}
\label{fig:quicksort}
\end{figure}