\begin{resumo}

A ordenação de dados é um dos problemas mais fundamentais da computação devido à sua importância teórica e prática. Aplicações como compiladores, sistemas operacionais e bancos de dados utilizam largamente rotinas ordenação. Além disso, um grande número de aplicações paralelas possui uma fase de computação intensa, na qual uma lista de elementos deve ser ordenada com base em algum de seus atributos. Embora existam diversos estudos sobre algoritmos de ordenação em arquiteturas paralelas, o desenvolvimento de soluções capazes de lidar com grandes volumes de dados é uma das preocupações atuais. O uso de \textit{clusters} é um caminho natural para permitir o processamento de dados em larga escala em tempos razoáveis. O modelo programação paralela MapReduce foi criado pela Google para processamento em tais ambientes. Este trabalho apresenta um projeto para comparação de desempenho de algoritmos de ordenação paralela implementados no modelo MapReduce, com o software Hadoop. Os experimentos avaliam a escalabilidade dos algoritmos em relação à quantidade de dados ordenados e de máquinas utilizadas e a influência de diferentes conjuntos de entrada no tempo de ordenação. Os resultados iniciais mostram que o algoritmo Ordenação por Amostragem apresenta boa escalabilidade em relação ao número de dados e máquinas, e que as distribuições das cargas de trabalho pouco influenciam no desempenho. 
    
\textbf{Palavras-chave:} Ordenação, Programação Paralela, MapReduce, Hadoop, Escalabilidade
\end{resumo}


\begin{abstract}

\textit{Sorting data is one of the most fundamental problems of computing due its theoretical and practical importance. Applications such as compilers, operating systems and databases make widely use of sorting routines. Moreover, a large number of applications has a phase of intense computation, in which a list of elements must be sorted based on one of its attributes. Although literature abounds with sorting algorithms in parallel architectures, the development of solutions able to handle large data volumes is one of the current concerns. Use of clusters is a natural way to allow large-scale data processing in a reasonable amount of time. MapReduce is a parallel programming model created by Google for computation in such environments. This work presents a project for performance comparison of sorting algorithms implemented in MapReduce model using the Hadoop software. 
The experiments measure the algorithms scalability relating to the amount of data sorted and machines used, and effect of different data sets in sorting time. Preliminar results presents that SampleSort algorithm demonstrates good scalability in number of machines and data, and the type of workload distribution has small influence on performance.}
	
\textbf{Keywords:} \textit{Sorting, Parallel Programming, MapReduce, Hadoop, Scalability.}
\end{abstract}
